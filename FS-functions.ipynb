{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "889b5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math \n",
    "import statistics\n",
    "from itertools import permutations\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d75cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"data/cars/cars.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b657de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = cars[cars.horsepower != \"?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f17601a",
   "metadata": {},
   "source": [
    "## FS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60cc6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isfloat(num):\n",
    "    try:\n",
    "        float(num)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def calculate_FS1_for_each_column(df,group_label):\n",
    "    \n",
    "    col = df.columns\n",
    "    colu = []\n",
    "    for c in col:\n",
    "        if (isfloat(df[c][0])):\n",
    "            colu.append(c)\n",
    "            \n",
    "    for c in colu:\n",
    "        df[c] = df[c].astype(float)\n",
    "    \n",
    "    string_columns_float = list(df.select_dtypes(exclude=['object']).columns)\n",
    "    string_columns_object = list(df.select_dtypes(include=['object']).columns)\n",
    "    \n",
    "    # print(f\"Group label is: {group_label}\")\n",
    "    # print(f\"Group label has {len(df[group_label].unique())} unique values\")\n",
    "    no_of_datasets = len(df[group_label].unique())\n",
    "    df = df.drop(labels=string_columns_object,axis=1)\n",
    "    list_of_datasets = []\n",
    "    origin_dict = {}\n",
    "    dict_of_mean_values = {} #key is the origin and the values are list of means for each column of a datas\n",
    "\n",
    "    #creating separated datasetst for each group\n",
    "    for count,value in enumerate(df[group_label].unique()):\n",
    "        list_of_datasets.append( df[df[group_label] == value])\n",
    "        list_of_datasets[count] = list_of_datasets[count].reset_index()\n",
    "    \n",
    "    \n",
    "    #drop origin column for each group and save it as a key in dictionary where \n",
    "    #the value of the key will be the corresponding dataset\n",
    "    \n",
    "    for dataset in list_of_datasets:\n",
    "        \n",
    "        group = int(dataset[group_label].unique()[0])\n",
    "        \n",
    "        origin_dict[group] = dataset.drop(labels=[group_label],axis=1)\n",
    "        \n",
    "        columns = origin_dict[group].columns\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(origin_dict[group])\n",
    "        origin_dict[group] = scaler.transform(origin_dict[group])\n",
    "        origin_dict[group] = pd.DataFrame(origin_dict[group], columns = columns)\n",
    "        origin_dict[group] = origin_dict[group].drop(labels=[\"index\"] ,axis=1)\n",
    "        dict_of_mean_values[group] = [origin_dict[group][c].mean() for c in origin_dict[group].columns]\n",
    "        \n",
    "    #calculation of diff and QDS between each combination of the groups.\n",
    "    diff = []\n",
    "\n",
    "    for key1, key2 in itertools.combinations(dict_of_mean_values.keys(), 2):\n",
    "        diff.append(abs(np.subtract(np.array(dict_of_mean_values[key1]),np.array(dict_of_mean_values[key2]))))\n",
    "            \n",
    "    #creation of the matrix W\n",
    "    D = origin_dict[1].shape[1]\n",
    "    W = np.ones((D, D))\n",
    "    \n",
    "    for row in range(len(W)):\n",
    "        for col in range(len(W[0])):\n",
    "            dij = abs(row-col)\n",
    "            W[row][col] = 1 - (dij/(D-1))\n",
    "            \n",
    "    #calculating QFD\n",
    "    QFD = []\n",
    "    for count,d in enumerate(diff):\n",
    "        QFD.append(math.sqrt(np.dot(np.dot(d,W),np.transpose(d))))\n",
    "        \n",
    "    tds = statistics.mean(QFD)\n",
    "    \n",
    "    return tds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "962010e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6268655640398301\n"
     ]
    }
   ],
   "source": [
    "print(calculate_FS1_for_each_column(cars,\"origin\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce40f2",
   "metadata": {},
   "source": [
    "# FS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632d4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FS2 funkcija\n",
    "\n",
    "def calculate_FS2_for_each_column(df, group_label):\n",
    "    \n",
    "    col = df.columns\n",
    "    colu = []\n",
    "    for c in col:\n",
    "        if (isfloat(df[c][0])):\n",
    "            colu.append(c)\n",
    "            \n",
    "    for c in colu:\n",
    "        df[c] = df[c].astype(float)\n",
    "    \n",
    "    string_columns_float = list(df.select_dtypes(exclude=['object']).columns)\n",
    "    string_columns_object = list(df.select_dtypes(include=['object']).columns)\n",
    "    \n",
    "    # print(f\"Group label is: {group_label}\")\n",
    "    # print(f\"Group label has {len(df[group_label].unique())} unique values\")\n",
    "    no_of_datasets = len(df[group_label].unique())\n",
    "    df = df.drop(labels=string_columns_object,axis=1)\n",
    "    list_of_datasets = []\n",
    "    origin_dict = {}\n",
    "    dict_of_mean_values = {} #key is the origin and the values are list of means for each column of a datas\n",
    "    dict_of_std_values_minus = {}\n",
    "    dict_of_std_values_plus = {}\n",
    "    final_dict = {}\n",
    "\n",
    "    #creating separated datasetst for each group\n",
    "    for count,value in enumerate(df[group_label].unique()):\n",
    "        list_of_datasets.append( df[df[group_label] == value])\n",
    "        list_of_datasets[count] = list_of_datasets[count].reset_index()\n",
    "    \n",
    "    \n",
    "    #drop origin column for each group and save it as a key in dictionary where \n",
    "    #the value of the key will be the corresponding dataset\n",
    "    \n",
    "    for dataset in list_of_datasets:\n",
    "        \n",
    "        group = int(dataset[group_label].unique()[0])\n",
    "        \n",
    "        origin_dict[group] = dataset.drop(labels=[group_label],axis=1)\n",
    "        \n",
    "        columns = origin_dict[group].columns\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(origin_dict[group])\n",
    "        origin_dict[group] = scaler.transform(origin_dict[group])\n",
    "        origin_dict[group] = pd.DataFrame(origin_dict[group], columns = columns)\n",
    "        origin_dict[group] = origin_dict[group].drop(labels=[\"index\"] ,axis=1)\n",
    "        dict_of_std_values_minus[group] = [origin_dict[group][c].mean() - origin_dict[group][c].std() for c in origin_dict[group].columns]\n",
    "        dict_of_mean_values[group] = [origin_dict[group][c].mean() for c in origin_dict[group].columns]\n",
    "        dict_of_std_values_plus[group] = [origin_dict[group][c].mean() + origin_dict[group][c].std() for c in origin_dict[group].columns]\n",
    "        matrix = np.array([dict_of_std_values_minus[group], dict_of_mean_values[group], dict_of_std_values_plus[group]])\n",
    "        final_dict[group] = matrix\n",
    "        \n",
    "    #calculation of diff and QDS between each combination of the groups.\n",
    "    diff = []\n",
    "\n",
    "    for key1, key2 in itertools.combinations(final_dict.keys(), 2):\n",
    "        diff.append(abs(np.subtract(np.array(final_dict[key1]),np.array(final_dict[key2]))))\n",
    "            \n",
    "    #creation of the matrix W\n",
    "    D = origin_dict[1].shape[1]\n",
    "    W = np.ones((D, D))\n",
    "        \n",
    "    for row in range(len(W)):\n",
    "        for col in range(len(W[0])):\n",
    "            dij = abs(row-col)\n",
    "            W[row][col] = 1 - (dij/(D-1))\n",
    "            \n",
    "    # print(diff)\n",
    "                        \n",
    "    #calculating QFD\n",
    "    QFD = []\n",
    "    for count,d in enumerate(diff):\n",
    "        # print(d.shape)\n",
    "        # print(W.shape)\n",
    "        QFD.append(np.sqrt(np.dot(np.dot(d,W),np.transpose(d))))\n",
    "            \n",
    "    TDS = sum(QFD)/len(QFD)\n",
    "    TDS = sum(TDS)/len(TDS)\n",
    "    TDS = sum(TDS)/len(TDS)\n",
    "    \n",
    "    return TDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c8c7c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625254807610549\n"
     ]
    }
   ],
   "source": [
    "print(calculate_FS2_for_each_column(cars,\"origin\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ca8d1",
   "metadata": {},
   "source": [
    "# FS3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5402ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FS3 funkcija\n",
    "\n",
    "def calc_hist(numbers):\n",
    "    range_0_2 = 0\n",
    "    range_2_4 = 0\n",
    "    range_4_6 = 0\n",
    "    range_6_8 = 0\n",
    "    range_8_10 = 0\n",
    "\n",
    "    # Iterate through the numbers and count occurrences in each range\n",
    "    for number in numbers:\n",
    "        if 0 <= number < 0.2:\n",
    "            range_0_2 += 1\n",
    "        elif 0.2 <= number < 0.4:\n",
    "            range_2_4 += 1\n",
    "        elif 0.4 <= number < 0.6:\n",
    "            range_4_6 += 1\n",
    "        elif 0.6 <= number < 0.8:\n",
    "            range_6_8 += 1\n",
    "        elif 0.8 <= number <= 1.0:\n",
    "            range_8_10 += 1\n",
    "\n",
    "    ranges = [range_0_2, range_2_4, range_4_6, range_6_8, range_8_10]\n",
    "    \n",
    "    return(np.array(ranges))\n",
    "\n",
    "def calculate_FS3_for_each_column(df, group_label):\n",
    "    \n",
    "    col = df.columns\n",
    "    colu = []\n",
    "    for c in col:\n",
    "        if (isfloat(df[c][0])):\n",
    "            colu.append(c)\n",
    "            \n",
    "    for c in colu:\n",
    "        df[c] = df[c].astype(float)\n",
    "    \n",
    "    string_columns_float = list(df.select_dtypes(exclude=['object']).columns)\n",
    "    string_columns_object = list(df.select_dtypes(include=['object']).columns)\n",
    "    \n",
    "    # print(f\"Group label is: {group_label}\")\n",
    "    # print(f\"Group label has {len(df[group_label].unique())} unique values\")\n",
    "    no_of_datasets = len(df[group_label].unique())\n",
    "    df = df.drop(labels=string_columns_object,axis=1)\n",
    "    list_of_datasets = []\n",
    "    origin_dict = {}\n",
    "    final_dict = {}\n",
    "\n",
    "    #creating separated datasetst for each group\n",
    "    for count,value in enumerate(df[group_label].unique()):\n",
    "        list_of_datasets.append( df[df[group_label] == value])\n",
    "        list_of_datasets[count] = list_of_datasets[count].reset_index()\n",
    "    \n",
    "    \n",
    "    #drop origin column for each group and save it as a key in dictionary where \n",
    "    #the value of the key will be the corresponding dataset\n",
    "    \n",
    "    for dataset in list_of_datasets:\n",
    "        \n",
    "        group = int(dataset[group_label].unique()[0])\n",
    "        \n",
    "        origin_dict[group] = dataset.drop(labels=[group_label],axis=1)\n",
    "        \n",
    "        columns = origin_dict[group].columns\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(origin_dict[group])\n",
    "        origin_dict[group] = scaler.transform(origin_dict[group])\n",
    "        origin_dict[group] = pd.DataFrame(origin_dict[group], columns = columns)\n",
    "        origin_dict[group] = origin_dict[group].drop(labels=[\"index\"] ,axis=1)\n",
    "\n",
    "        final_dict[group] = [(calc_hist(origin_dict[group][c]) / origin_dict[group][c].shape[0]) for c in origin_dict[group].columns]\n",
    "        \n",
    "    #calculation of diff and QDS between each combination of the groups.\n",
    "    diff = []\n",
    "\n",
    "    for key1, key2 in itertools.combinations(final_dict.keys(), 2):\n",
    "        diff.append(abs(np.subtract(np.array(final_dict[key1]),np.array(final_dict[key2]))))\n",
    "            \n",
    "    # print(diff)\n",
    "    \n",
    "    #creation of the matrix W\n",
    "    D = len(final_dict[1])\n",
    "    W = np.ones((D, D))\n",
    "        \n",
    "    for row in range(len(W)):\n",
    "        for col in range(len(W[0])):\n",
    "            dij = abs(row-col)\n",
    "            W[row][col] = 1 - (dij/(D-1))\n",
    "                        \n",
    "    #calculating QFD\n",
    "    QFD = []\n",
    "    for count,d in enumerate(diff):\n",
    "        # print(W.shape)\n",
    "        # print(d.shape)\n",
    "        # QFD.append(np.sqrt(np.dot(np.dot(d,W),np.transpose(d))))\n",
    "        QFD.append(np.sqrt(np.dot(np.dot(np.transpose(d),W),d)))\n",
    "        \n",
    "    TDS = sum(QFD)/len(QFD)\n",
    "    TDS = sum(TDS)/len(TDS)\n",
    "    TDS = sum(TDS)/len(TDS)\n",
    "    \n",
    "    return TDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ac3d4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6213322709152201\n"
     ]
    }
   ],
   "source": [
    "print(calculate_FS3_for_each_column(cars,\"origin\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef463c7e",
   "metadata": {},
   "source": [
    "# Run the combinations for cars - fs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdffcc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"data/cars/cars.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d631613",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = cars[cars.horsepower != \"?\"]\n",
    "df = cars.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2186fb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
       "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
       "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
       "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
       "3  16.0          8         304.0      150.0  3433.0          12.0          70   \n",
       "4  17.0          8         302.0      140.0  3449.0          10.5          70   \n",
       "\n",
       "   origin                   car_name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff456159",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_order = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "828cc4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_keys = [i for i in range(0, len(df.columns.tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59fc71c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds_list = []\n",
    "permutations_list = list(permutations(col_keys))\n",
    "permutations_list = [list(tup) for tup in permutations_list]\n",
    "\n",
    "# permutations_list = permutations_list[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "710d0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations_list_names = permutations_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "312ed119",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(permutations_list)):\n",
    "    permutations_list_names[i] = [og_order[index] for index in permutations_list[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41ca44c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining time: 3338.92s\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      6\u001b[0m subset \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, permutations_list[i]]\n\u001b[1;32m----> 7\u001b[0m tds_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcalculate_FS1_for_each_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morigin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      9\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     10\u001b[0m total_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (end_time \u001b[38;5;241m-\u001b[39m start_time)\n",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m, in \u001b[0;36mcalculate_FS1_for_each_column\u001b[1;34m(df, group_label)\u001b[0m\n\u001b[0;32m     14\u001b[0m         colu\u001b[38;5;241m.\u001b[39mappend(c)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m colu:\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m df[c]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     19\u001b[0m string_columns_float \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mselect_dtypes(exclude\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     20\u001b[0m string_columns_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3979\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4187\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4184\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(existing_piece, DataFrame):\n\u001b[0;32m   4185\u001b[0m             value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(value, (\u001b[38;5;28mlen\u001b[39m(existing_piece\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m-> 4187\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4146\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis), key, value)\n\u001b[0;32m   4145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iset_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4148\u001b[0m \u001b[38;5;66;03m# check if we are modifying a copy\u001b[39;00m\n\u001b[0;32m   4149\u001b[0m \u001b[38;5;66;03m# try to set first as we want an invalid\u001b[39;00m\n\u001b[0;32m   4150\u001b[0m \u001b[38;5;66;03m# value exception to occur first\u001b[39;00m\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4136\u001b[0m, in \u001b[0;36mDataFrame._iset_item_mgr\u001b[1;34m(self, loc, value, inplace)\u001b[0m\n\u001b[0;32m   4132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iset_item_mgr\u001b[39m(\n\u001b[0;32m   4133\u001b[0m     \u001b[38;5;28mself\u001b[39m, loc: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mslice\u001b[39m \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray, value, inplace: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   4134\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4135\u001b[0m     \u001b[38;5;66;03m# when called from _set_item_mgr loc can be anything returned from get_loc\u001b[39;00m\n\u001b[1;32m-> 4136\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1330\u001b[0m, in \u001b[0;36mBlockManager.iset\u001b[1;34m(self, loc, value, inplace)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blknos[unfit_idxr] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs[unfit_idxr] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(unfit_count)\n\u001b[1;32m-> 1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;66;03m# TODO(CoW) is this always correct to assume that the new_blocks\u001b[39;00m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;66;03m# are not referencing anything else?\u001b[39;00m\n\u001b[0;32m   1333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_time = 0\n",
    "\n",
    "for i in range(len(permutations_list)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    subset = df.iloc[:, permutations_list[i]]\n",
    "    tds_list.append(calculate_FS1_for_each_column(subset,\"origin\"))\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time += (end_time - start_time)\n",
    "\n",
    "    average_time = total_time / (i + 1)\n",
    "\n",
    "    remaining_time = average_time * (len(permutations_list) - i)\n",
    "\n",
    "    # Print remaining time dynamically\n",
    "    print(f\"Remaining time: {remaining_time:.2f}s\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "10a947c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the resulting dictionary along with the actual column names\n",
    "result_dict_cols = {\n",
    "    index: {\"columns_order\": permutations_list_names[index], \"tds\": tds_list[index]}\n",
    "    for index, _ in enumerate(permutations_list_names)\n",
    "}\n",
    "\n",
    "# the resulting dictionary along with the indexes of the column names as was ordered in the original ordering\n",
    "result_dict_indexes = {\n",
    "    index: {\"columns_order\": permutations_list[index], \"tds\": tds_list[index]}\n",
    "    for index, _ in enumerate(permutations_list)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9d000aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_dict_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "fc5a8f4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# result_dict_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25c0ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'results/cars_results.json'\n",
    "\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(result_dict_cols, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0808fc",
   "metadata": {},
   "source": [
    "# Run the combinations for glass data set - fs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "6d274025",
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = pd.read_csv(\"data/glass/glass.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "73810d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = glass.copy()\n",
    "df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "544f4aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>type_of_glass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51596</td>\n",
       "      <td>12.79</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>72.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba    Fe  type_of_glass\n",
       "0  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.00              1\n",
       "1  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.00              1\n",
       "2  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.00              1\n",
       "3  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.00              1\n",
       "4  1.51596  12.79  3.61  1.62  72.97  0.64  8.07  0.0  0.26              1"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "584f6239",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_order = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "31821524",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_keys = [i for i in range(0, len(df.columns.tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "7de3d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds_list = []\n",
    "permutations_list = list(permutations(col_keys))\n",
    "permutations_list = [list(tup) for tup in permutations_list]\n",
    "\n",
    "permutations_list = permutations_list[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "c63aa5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations_list_names = permutations_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "d03897e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(permutations_list)):\n",
    "    permutations_list_names[i] = [og_order[index] for index in permutations_list[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "ae6b304f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining time: 99.00s\r"
     ]
    }
   ],
   "source": [
    "for i in range(len(permutations_list)):\n",
    "    cols_ordering = permutations_list[i]\n",
    "    subset = df.iloc[:, cols_ordering]\n",
    "    tds_list.append(calculate_FS2_for_each_column(subset,\"type_of_glass\"))\n",
    "    \n",
    "    remaining_time = i\n",
    "    print(f\"Remaining time: {remaining_time:.2f}s\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "771cfc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the resulting dictionary along with the actual column names\n",
    "result_dict_cols = {\n",
    "    index: {\"columns_order\": permutations_list_names[index], \"tds\": tds_list[index]}\n",
    "    for index, _ in enumerate(permutations_list_names)\n",
    "}\n",
    "\n",
    "# the resulting dictionary along with the indexes of the column names as was ordered in the original ordering\n",
    "result_dict_indexes = {\n",
    "    index: {\"columns_order\": permutations_list[index], \"tds\": tds_list[index]}\n",
    "    for index, _ in enumerate(permutations_list)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "8d93448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_dict_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "71614e4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# result_dict_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "d7d80bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'results/glass_results.json'\n",
    "\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(result_dict_cols, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd52746",
   "metadata": {},
   "source": [
    "# Run the combinations for seeds data set - fs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "f023ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = pd.read_csv(\"data/seeds/seeds.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "d564db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = seeds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "6d7ce4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length_kernel</th>\n",
       "      <th>width_kernel</th>\n",
       "      <th>asymmetry_coeff</th>\n",
       "      <th>length_groove</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    area  perimeter  compactness  length_kernel  width_kernel  \\\n",
       "0  15.26      14.84       0.8710          5.763         3.312   \n",
       "1  14.88      14.57       0.8811          5.554         3.333   \n",
       "2  14.29      14.09       0.9050          5.291         3.337   \n",
       "3  13.84      13.94       0.8955          5.324         3.379   \n",
       "4  16.14      14.99       0.9034          5.658         3.562   \n",
       "\n",
       "   asymmetry_coeff  length_groove  class  \n",
       "0            2.221          5.220      1  \n",
       "1            1.018          4.956      1  \n",
       "2            2.699          4.825      1  \n",
       "3            2.259          4.805      1  \n",
       "4            1.355          5.175      1  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "f1339274",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_order = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "bae280be",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_keys = [i for i in range(0, len(df.columns.tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "5e3a6d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds_list = []\n",
    "permutations_list = list(permutations(col_keys))\n",
    "permutations_list = [list(tup) for tup in permutations_list]\n",
    "\n",
    "permutations_list = permutations_list[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "8980f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations_list_names = permutations_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "e92dce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(permutations_list)):\n",
    "    permutations_list_names[i] = [og_order[index] for index in permutations_list[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "2fc750e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols_ordering in permutations_list:\n",
    "    subset = df.iloc[:, cols_ordering]\n",
    "    tds_list.append(calculate_FS3_for_each_column(subset,\"class\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "45065ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the resulting dictionary along with the actual column names\n",
    "result_dict_cols = {\n",
    "    index: {\"columns_order\": permutations_list_names[index], \"tds\": tds_list[index]}\n",
    "    for index, _ in enumerate(permutations_list_names)\n",
    "}\n",
    "\n",
    "# the resulting dictionary along with the indexes of the column names as was ordered in the original ordering\n",
    "result_dict_indexes = {\n",
    "    index: {\"columns_order\": permutations_list[index], \"tds\": tds_list[index]}\n",
    "    for index, _ in enumerate(permutations_list)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "4cd569f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_dict_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "197d7d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# result_dict_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a82486",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'results/seeds_results.json'\n",
    "\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(result_dict_cols, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
