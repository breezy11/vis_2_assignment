{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "889b5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31d75cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"data/cars/cars.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65b657de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = cars[cars.horsepower != \"?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60cc6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def isfloat(num):\n",
    "    try:\n",
    "        float(num)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def calculate_FS1_for_each_column(df,group_label):\n",
    "    \n",
    "    col = df.columns\n",
    "    colu = []\n",
    "    for c in col:\n",
    "        if (isfloat(df[c][0])):\n",
    "            colu.append(c)\n",
    "            \n",
    "    for c in colu:\n",
    "        df[c] = df[c].astype(float)\n",
    "    \n",
    "    string_columns_float = list(df.select_dtypes(exclude=['object']).columns)\n",
    "    string_columns_object = list(df.select_dtypes(include=['object']).columns)\n",
    "    \n",
    "    print(f\"Group label is: {group_label}\")\n",
    "    print(f\"Group label has {len(df[group_label].unique())} unique values\")\n",
    "    no_of_datasets = len(df[group_label].unique())\n",
    "    df = df.drop(labels=string_columns_object,axis=1)\n",
    "    list_of_datasets = []\n",
    "    origin_dict = {}\n",
    "    dict_of_mean_values = {} #key is the origin and the values are list of means for each column of a datas\n",
    "\n",
    "    #creating separated datasetst for each group\n",
    "    for count,value in enumerate(df[group_label].unique()):\n",
    "        list_of_datasets.append( df[df[group_label] == value])\n",
    "        list_of_datasets[count] = list_of_datasets[count].reset_index()\n",
    "    \n",
    "    \n",
    "    #drop origin column for each group and save it as a key in dictionary where \n",
    "    #the value of the key will be the corresponding dataset\n",
    "    \n",
    "    for dataset in list_of_datasets:\n",
    "        \n",
    "        group = int(dataset[group_label].unique()[0])\n",
    "        \n",
    "        origin_dict[group] = dataset.drop(labels=[group_label],axis=1)\n",
    "        \n",
    "        columns = origin_dict[group].columns\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(origin_dict[group])\n",
    "        origin_dict[group] = scaler.transform(origin_dict[group])\n",
    "        origin_dict[group] = pd.DataFrame(origin_dict[group], columns = columns)\n",
    "        origin_dict[group] = origin_dict[group].drop(labels=[\"index\"] ,axis=1)\n",
    "        dict_of_mean_values[group] = [origin_dict[group][c].mean() for c in origin_dict[group].columns]\n",
    "        \n",
    "    #calculation of diff and QDS between each combination of the groups.\n",
    "    diff = []\n",
    "\n",
    "    for key1, key2 in itertools.combinations(dict_of_mean_values.keys(), 2):\n",
    "        diff.append(abs(np.subtract(np.array(dict_of_mean_values[key1]),np.array(dict_of_mean_values[key2]))))\n",
    "            \n",
    "    #creation of the matrix W\n",
    "    D = origin_dict[1].shape[1]\n",
    "    W = np.ones((D, D))\n",
    "    \n",
    "    for row in range(len(W)):\n",
    "        for col in range(len(W[0])):\n",
    "            dij = abs(row-col)\n",
    "            W[row][col] = 1 - (dij/(D-1))\n",
    "            \n",
    "    #calculating QFD\n",
    "    QFD = []\n",
    "    for count,d in enumerate(diff):\n",
    "        QFD.append(math.sqrt(np.dot(np.dot(d,W),np.transpose(d))))\n",
    "    \n",
    "    return origin_dict, dict_of_mean_values, diff, QFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "962010e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group label is: origin\n",
      "Group label has 3 unique values\n"
     ]
    }
   ],
   "source": [
    "datasets,dict_of_mean_values,diff,QFD = calculate_FS1_for_each_column(cars,\"origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81d9a48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.44511152122143616, 0.7805869893625766, 0.6548981815354775]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c40ee18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(datasets.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51649e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36778231292517016, 0.5693877551020409, 0.43922228350799786, 0.3766796606282962, 0.47080532811927156, 0.492267893072722, 0.46598639455782315]\n"
     ]
    }
   ],
   "source": [
    "print(dict_of_mean_values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "632d4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FS2 funkcija\n",
    "\n",
    "def calculate_FS2_for_each_column(df, group_label):\n",
    "    \n",
    "    col = df.columns\n",
    "    colu = []\n",
    "    for c in col:\n",
    "        if (isfloat(df[c][0])):\n",
    "            colu.append(c)\n",
    "            \n",
    "    for c in colu:\n",
    "        df[c] = df[c].astype(float)\n",
    "    \n",
    "    string_columns_float = list(df.select_dtypes(exclude=['object']).columns)\n",
    "    string_columns_object = list(df.select_dtypes(include=['object']).columns)\n",
    "    \n",
    "    print(f\"Group label is: {group_label}\")\n",
    "    print(f\"Group label has {len(df[group_label].unique())} unique values\")\n",
    "    no_of_datasets = len(df[group_label].unique())\n",
    "    df = df.drop(labels=string_columns_object,axis=1)\n",
    "    list_of_datasets = []\n",
    "    origin_dict = {}\n",
    "    dict_of_mean_values = {} #key is the origin and the values are list of means for each column of a datas\n",
    "    dict_of_std_values_minus = {}\n",
    "    dict_of_std_values_plus = {}\n",
    "    final_dict = {}\n",
    "\n",
    "    #creating separated datasetst for each group\n",
    "    for count,value in enumerate(df[group_label].unique()):\n",
    "        list_of_datasets.append( df[df[group_label] == value])\n",
    "        list_of_datasets[count] = list_of_datasets[count].reset_index()\n",
    "    \n",
    "    \n",
    "    #drop origin column for each group and save it as a key in dictionary where \n",
    "    #the value of the key will be the corresponding dataset\n",
    "    \n",
    "    for dataset in list_of_datasets:\n",
    "        \n",
    "        group = int(dataset[group_label].unique()[0])\n",
    "        \n",
    "        origin_dict[group] = dataset.drop(labels=[group_label],axis=1)\n",
    "        \n",
    "        columns = origin_dict[group].columns\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(origin_dict[group])\n",
    "        origin_dict[group] = scaler.transform(origin_dict[group])\n",
    "        origin_dict[group] = pd.DataFrame(origin_dict[group], columns = columns)\n",
    "        origin_dict[group] = origin_dict[group].drop(labels=[\"index\"] ,axis=1)\n",
    "        dict_of_std_values_minus[group] = [origin_dict[group][c].mean() - origin_dict[group][c].std() for c in origin_dict[group].columns]\n",
    "        dict_of_mean_values[group] = [origin_dict[group][c].mean() for c in origin_dict[group].columns]\n",
    "        dict_of_std_values_plus[group] = [origin_dict[group][c].mean() + origin_dict[group][c].std() for c in origin_dict[group].columns]\n",
    "        matrix = np.array([dict_of_std_values_minus[group], dict_of_mean_values[group], dict_of_std_values_plus[group]])\n",
    "        final_dict[group] = matrix\n",
    "        \n",
    "    #calculation of diff and QDS between each combination of the groups.\n",
    "    diff = []\n",
    "\n",
    "    for key1, key2 in itertools.combinations(final_dict.keys(), 2):\n",
    "        diff.append(abs(np.subtract(np.array(final_dict[key1]),np.array(final_dict[key2]))))\n",
    "            \n",
    "    #creation of the matrix W\n",
    "    D = origin_dict[1].shape[1]\n",
    "    W = np.ones((D, D))\n",
    "        \n",
    "    for row in range(len(W)):\n",
    "        for col in range(len(W[0])):\n",
    "            dij = abs(row-col)\n",
    "            W[row][col] = 1 - (dij/(D-1))\n",
    "            \n",
    "    print(diff)\n",
    "                        \n",
    "    #calculating QFD\n",
    "    QFD = []\n",
    "    for count,d in enumerate(diff):\n",
    "        print(d.shape)\n",
    "        print(W.shape)\n",
    "        QFD.append(np.sqrt(np.dot(np.dot(d,W),np.transpose(d))))\n",
    "    \n",
    "    return origin_dict, dict_of_mean_values, diff, QFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9c8c7c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group label is: origin\n",
      "Group label has 3 unique values\n",
      "[array([[0.06929523, 0.01489528, 0.07570012, 0.02733172, 0.01420332,\n",
      "        0.00613054, 0.15508121],\n",
      "       [0.0675545 , 0.20229915, 0.1054584 , 0.02873662, 0.00897705,\n",
      "        0.00483126, 0.15426677],\n",
      "       [0.06581378, 0.41949357, 0.13521668, 0.03014152, 0.00375077,\n",
      "        0.01579307, 0.15345233]]), array([[0.01852559, 0.327994  , 0.00865215, 0.01299342, 0.17420303,\n",
      "        0.18004248, 0.02686108],\n",
      "       [0.03801631, 0.4885054 , 0.07720182, 0.0205482 , 0.16580754,\n",
      "        0.12765538, 0.00705282],\n",
      "       [0.05750702, 0.64901681, 0.1457515 , 0.02810298, 0.15741205,\n",
      "        0.07526829, 0.01275544]]), array([[0.05076964, 0.34288928, 0.06704796, 0.04032514, 0.15999971,\n",
      "        0.17391193, 0.12822012],\n",
      "       [0.0295382 , 0.28620625, 0.02825658, 0.04928482, 0.15683049,\n",
      "        0.13248664, 0.14721395],\n",
      "       [0.00830676, 0.22952323, 0.01053481, 0.0582445 , 0.15366128,\n",
      "        0.09106136, 0.16620777]])]\n",
      "(3, 7)\n",
      "(7, 7)\n",
      "(3, 7)\n",
      "(7, 7)\n",
      "(3, 7)\n",
      "(7, 7)\n"
     ]
    }
   ],
   "source": [
    "datasets,dict_of_mean_values,diff,QFD  = calculate_FS2_for_each_column(cars,\"origin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e216d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(QFD)):\n",
    "    QFD[i] = QFD[i].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60d809db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.44058384361353387, 0.7767591205481543, 0.658421458669959]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QFD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ca8d1",
   "metadata": {},
   "source": [
    "# FS3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5402ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FS3 funkcija\n",
    "\n",
    "def calc_hist(numbers):\n",
    "    range_0_2 = 0\n",
    "    range_2_4 = 0\n",
    "    range_4_6 = 0\n",
    "    range_6_8 = 0\n",
    "    range_8_10 = 0\n",
    "\n",
    "    # Iterate through the numbers and count occurrences in each range\n",
    "    for number in numbers:\n",
    "        if 0 <= number < 0.2:\n",
    "            range_0_2 += 1\n",
    "        elif 0.2 <= number < 0.4:\n",
    "            range_2_4 += 1\n",
    "        elif 0.4 <= number < 0.6:\n",
    "            range_4_6 += 1\n",
    "        elif 0.6 <= number < 0.8:\n",
    "            range_6_8 += 1\n",
    "        elif 0.8 <= number <= 1.0:\n",
    "            range_8_10 += 1\n",
    "\n",
    "    ranges = [range_0_2, range_2_4, range_4_6, range_6_8, range_8_10]\n",
    "    \n",
    "    return(np.array(ranges))\n",
    "\n",
    "def calculate_FS3_for_each_column(df, group_label):\n",
    "    \n",
    "    col = df.columns\n",
    "    colu = []\n",
    "    for c in col:\n",
    "        if (isfloat(df[c][0])):\n",
    "            colu.append(c)\n",
    "            \n",
    "    for c in colu:\n",
    "        df[c] = df[c].astype(float)\n",
    "    \n",
    "    string_columns_float = list(df.select_dtypes(exclude=['object']).columns)\n",
    "    string_columns_object = list(df.select_dtypes(include=['object']).columns)\n",
    "    \n",
    "    print(f\"Group label is: {group_label}\")\n",
    "    print(f\"Group label has {len(df[group_label].unique())} unique values\")\n",
    "    no_of_datasets = len(df[group_label].unique())\n",
    "    df = df.drop(labels=string_columns_object,axis=1)\n",
    "    list_of_datasets = []\n",
    "    origin_dict = {}\n",
    "    final_dict = {}\n",
    "\n",
    "    #creating separated datasetst for each group\n",
    "    for count,value in enumerate(df[group_label].unique()):\n",
    "        list_of_datasets.append( df[df[group_label] == value])\n",
    "        list_of_datasets[count] = list_of_datasets[count].reset_index()\n",
    "    \n",
    "    \n",
    "    #drop origin column for each group and save it as a key in dictionary where \n",
    "    #the value of the key will be the corresponding dataset\n",
    "    \n",
    "    for dataset in list_of_datasets:\n",
    "        \n",
    "        group = int(dataset[group_label].unique()[0])\n",
    "        \n",
    "        origin_dict[group] = dataset.drop(labels=[group_label],axis=1)\n",
    "        \n",
    "        columns = origin_dict[group].columns\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(origin_dict[group])\n",
    "        origin_dict[group] = scaler.transform(origin_dict[group])\n",
    "        origin_dict[group] = pd.DataFrame(origin_dict[group], columns = columns)\n",
    "        origin_dict[group] = origin_dict[group].drop(labels=[\"index\"] ,axis=1)\n",
    "\n",
    "        ranges = [range_0_2, range_2_4, range_4_6, range_6_8, range_8_10]\n",
    "        final_dict[group] = [calc_hist(origin_dict[group][c]) for c in origin_dict[group].columns]\n",
    "        \n",
    "        # dict_of_std_values_minus[group] = [origin_dict[group][c].mean() - origin_dict[group][c].std() for c in origin_dict[group].columns]\n",
    "        # dict_of_mean_values[group] = [origin_dict[group][c].mean() for c in origin_dict[group].columns]\n",
    "        # dict_of_std_values_plus[group] = [origin_dict[group][c].mean() + origin_dict[group][c].std() for c in origin_dict[group].columns]\n",
    "        # matrix = np.array([dict_of_std_values_minus[group], dict_of_mean_values[group], dict_of_std_values_plus[group]])\n",
    "        # final_dict[group] = matrix\n",
    "        \n",
    "    #calculation of diff and QDS between each combination of the groups.\n",
    "    diff = []\n",
    "\n",
    "    for key1, key2 in itertools.combinations(final_dict.keys(), 2):\n",
    "        diff.append(abs(np.subtract(np.array(final_dict[key1]),np.array(final_dict[key2]))))\n",
    "            \n",
    "    print(diff)\n",
    "    #creation of the matrix W\n",
    "    D = origin_dict[1].shape[1]\n",
    "    W = np.ones((D, D))\n",
    "        \n",
    "    for row in range(len(W)):\n",
    "        for col in range(len(W[0])):\n",
    "            dij = abs(row-col)\n",
    "            W[row][col] = 1 - (dij/(D-1))\n",
    "                        \n",
    "    #calculating QFD\n",
    "    QFD = []\n",
    "    for count,d in enumerate(diff):\n",
    "        print(W.shape)\n",
    "        print(d.shape)\n",
    "        QFD.append(np.sqrt(np.dot(np.dot(d,W),np.transpose(d))))\n",
    "    \n",
    "    return origin_dict, dict_of_mean_values, diff, QFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c09b6092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group label is: origin\n",
      "Group label has 3 unique values\n",
      "[array([[42, 91,  8, 13, 12],\n",
      "       [65, 69, 73,  0, 97],\n",
      "       [46, 18, 37, 44, 21],\n",
      "       [30, 71, 34, 22,  9],\n",
      "       [27, 34, 47, 48, 10],\n",
      "       [ 8, 45, 73, 31,  9],\n",
      "       [48, 33, 46, 35,  4]]), array([[41, 84, 22, 21,  9],\n",
      "       [ 8,  0, 70,  0, 99],\n",
      "       [53, 28, 28, 47, 21],\n",
      "       [45, 62, 43, 17, 10],\n",
      "       [ 4, 49, 55, 52, 17],\n",
      "       [11, 49, 88, 41, 10],\n",
      "       [45, 30, 42, 35, 25]]), array([[ 1,  7, 14,  8,  3],\n",
      "       [57, 69,  3,  0,  2],\n",
      "       [ 7, 10,  9,  3,  0],\n",
      "       [15,  9,  9,  5,  1],\n",
      "       [23, 15,  8,  4,  7],\n",
      "       [19,  4, 15, 10,  1],\n",
      "       [ 3,  3,  4,  0, 21]])]\n",
      "(7, 7)\n",
      "(7, 5)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (7,5) and (7,7) not aligned: 5 (dim 1) != 7 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m datasets,dict_of_mean_values,diff,QFD  \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_FS3_for_each_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morigin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[117], line 77\u001b[0m, in \u001b[0;36mcalculate_FS3_for_each_column\u001b[1;34m(df, group_label)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mprint\u001b[39m(W\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(d\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 77\u001b[0m     QFD\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mdot(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m,np\u001b[38;5;241m.\u001b[39mtranspose(d))))\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m origin_dict, dict_of_mean_values, diff, QFD\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (7,5) and (7,7) not aligned: 5 (dim 1) != 7 (dim 0)"
     ]
    }
   ],
   "source": [
    "datasets,dict_of_mean_values,diff,QFD  = calculate_FS3_for_each_column(cars, \"origin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
