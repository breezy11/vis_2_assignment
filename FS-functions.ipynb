{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "889b5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math \n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d75cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"data/cars/cars.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b657de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = cars[cars.horsepower != \"?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f17601a",
   "metadata": {},
   "source": [
    "## FS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60cc6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isfloat(num):\n",
    "    try:\n",
    "        float(num)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def calculate_FS1_for_each_column(df,group_label):\n",
    "    \n",
    "    col = df.columns\n",
    "    colu = []\n",
    "    for c in col:\n",
    "        if (isfloat(df[c][0])):\n",
    "            colu.append(c)\n",
    "            \n",
    "    for c in colu:\n",
    "        df[c] = df[c].astype(float)\n",
    "    \n",
    "    string_columns_float = list(df.select_dtypes(exclude=['object']).columns)\n",
    "    string_columns_object = list(df.select_dtypes(include=['object']).columns)\n",
    "    \n",
    "    print(f\"Group label is: {group_label}\")\n",
    "    print(f\"Group label has {len(df[group_label].unique())} unique values\")\n",
    "    no_of_datasets = len(df[group_label].unique())\n",
    "    df = df.drop(labels=string_columns_object,axis=1)\n",
    "    list_of_datasets = []\n",
    "    origin_dict = {}\n",
    "    dict_of_mean_values = {} #key is the origin and the values are list of means for each column of a datas\n",
    "\n",
    "    #creating separated datasetst for each group\n",
    "    for count,value in enumerate(df[group_label].unique()):\n",
    "        list_of_datasets.append( df[df[group_label] == value])\n",
    "        list_of_datasets[count] = list_of_datasets[count].reset_index()\n",
    "    \n",
    "    \n",
    "    #drop origin column for each group and save it as a key in dictionary where \n",
    "    #the value of the key will be the corresponding dataset\n",
    "    \n",
    "    for dataset in list_of_datasets:\n",
    "        \n",
    "        group = int(dataset[group_label].unique()[0])\n",
    "        \n",
    "        origin_dict[group] = dataset.drop(labels=[group_label],axis=1)\n",
    "        \n",
    "        columns = origin_dict[group].columns\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(origin_dict[group])\n",
    "        origin_dict[group] = scaler.transform(origin_dict[group])\n",
    "        origin_dict[group] = pd.DataFrame(origin_dict[group], columns = columns)\n",
    "        origin_dict[group] = origin_dict[group].drop(labels=[\"index\"] ,axis=1)\n",
    "        dict_of_mean_values[group] = [origin_dict[group][c].mean() for c in origin_dict[group].columns]\n",
    "        \n",
    "    #calculation of diff and QDS between each combination of the groups.\n",
    "    diff = []\n",
    "\n",
    "    for key1, key2 in itertools.combinations(dict_of_mean_values.keys(), 2):\n",
    "        diff.append(abs(np.subtract(np.array(dict_of_mean_values[key1]),np.array(dict_of_mean_values[key2]))))\n",
    "            \n",
    "    #creation of the matrix W\n",
    "    D = origin_dict[1].shape[1]\n",
    "    W = np.ones((D, D))\n",
    "    \n",
    "    for row in range(len(W)):\n",
    "        for col in range(len(W[0])):\n",
    "            dij = abs(row-col)\n",
    "            W[row][col] = 1 - (dij/(D-1))\n",
    "            \n",
    "    #calculating QFD\n",
    "    QFD = []\n",
    "    for count,d in enumerate(diff):\n",
    "        QFD.append(math.sqrt(np.dot(np.dot(d,W),np.transpose(d))))\n",
    "        \n",
    "    tds = statistics.mean(QFD)\n",
    "    \n",
    "    return tds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "962010e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group label is: origin\n",
      "Group label has 3 unique values\n",
      "0.6268655640398301\n"
     ]
    }
   ],
   "source": [
    "print(calculate_FS1_for_each_column(cars,\"origin\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce40f2",
   "metadata": {},
   "source": [
    "# FS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632d4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FS2 funkcija\n",
    "\n",
    "def calculate_FS2_for_each_column(df, group_label):\n",
    "    \n",
    "    col = df.columns\n",
    "    colu = []\n",
    "    for c in col:\n",
    "        if (isfloat(df[c][0])):\n",
    "            colu.append(c)\n",
    "            \n",
    "    for c in colu:\n",
    "        df[c] = df[c].astype(float)\n",
    "    \n",
    "    string_columns_float = list(df.select_dtypes(exclude=['object']).columns)\n",
    "    string_columns_object = list(df.select_dtypes(include=['object']).columns)\n",
    "    \n",
    "    print(f\"Group label is: {group_label}\")\n",
    "    print(f\"Group label has {len(df[group_label].unique())} unique values\")\n",
    "    no_of_datasets = len(df[group_label].unique())\n",
    "    df = df.drop(labels=string_columns_object,axis=1)\n",
    "    list_of_datasets = []\n",
    "    origin_dict = {}\n",
    "    dict_of_mean_values = {} #key is the origin and the values are list of means for each column of a datas\n",
    "    dict_of_std_values_minus = {}\n",
    "    dict_of_std_values_plus = {}\n",
    "    final_dict = {}\n",
    "\n",
    "    #creating separated datasetst for each group\n",
    "    for count,value in enumerate(df[group_label].unique()):\n",
    "        list_of_datasets.append( df[df[group_label] == value])\n",
    "        list_of_datasets[count] = list_of_datasets[count].reset_index()\n",
    "    \n",
    "    \n",
    "    #drop origin column for each group and save it as a key in dictionary where \n",
    "    #the value of the key will be the corresponding dataset\n",
    "    \n",
    "    for dataset in list_of_datasets:\n",
    "        \n",
    "        group = int(dataset[group_label].unique()[0])\n",
    "        \n",
    "        origin_dict[group] = dataset.drop(labels=[group_label],axis=1)\n",
    "        \n",
    "        columns = origin_dict[group].columns\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(origin_dict[group])\n",
    "        origin_dict[group] = scaler.transform(origin_dict[group])\n",
    "        origin_dict[group] = pd.DataFrame(origin_dict[group], columns = columns)\n",
    "        origin_dict[group] = origin_dict[group].drop(labels=[\"index\"] ,axis=1)\n",
    "        dict_of_std_values_minus[group] = [origin_dict[group][c].mean() - origin_dict[group][c].std() for c in origin_dict[group].columns]\n",
    "        dict_of_mean_values[group] = [origin_dict[group][c].mean() for c in origin_dict[group].columns]\n",
    "        dict_of_std_values_plus[group] = [origin_dict[group][c].mean() + origin_dict[group][c].std() for c in origin_dict[group].columns]\n",
    "        matrix = np.array([dict_of_std_values_minus[group], dict_of_mean_values[group], dict_of_std_values_plus[group]])\n",
    "        final_dict[group] = matrix\n",
    "        \n",
    "    #calculation of diff and QDS between each combination of the groups.\n",
    "    diff = []\n",
    "\n",
    "    for key1, key2 in itertools.combinations(final_dict.keys(), 2):\n",
    "        diff.append(abs(np.subtract(np.array(final_dict[key1]),np.array(final_dict[key2]))))\n",
    "            \n",
    "    #creation of the matrix W\n",
    "    D = origin_dict[1].shape[1]\n",
    "    W = np.ones((D, D))\n",
    "        \n",
    "    for row in range(len(W)):\n",
    "        for col in range(len(W[0])):\n",
    "            dij = abs(row-col)\n",
    "            W[row][col] = 1 - (dij/(D-1))\n",
    "            \n",
    "    # print(diff)\n",
    "                        \n",
    "    #calculating QFD\n",
    "    QFD = []\n",
    "    for count,d in enumerate(diff):\n",
    "        # print(d.shape)\n",
    "        # print(W.shape)\n",
    "        QFD.append(np.sqrt(np.dot(np.dot(d,W),np.transpose(d))))\n",
    "            \n",
    "    TDS = sum(QFD)/len(QFD)\n",
    "    TDS = sum(TDS)/len(TDS)\n",
    "    TDS = sum(TDS)/len(TDS)\n",
    "    \n",
    "    return TDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c8c7c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group label is: origin\n",
      "Group label has 3 unique values\n",
      "0.625254807610549\n"
     ]
    }
   ],
   "source": [
    "print(calculate_FS2_for_each_column(cars,\"origin\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ca8d1",
   "metadata": {},
   "source": [
    "# FS3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5402ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FS3 funkcija\n",
    "\n",
    "def calc_hist(numbers):\n",
    "    range_0_2 = 0\n",
    "    range_2_4 = 0\n",
    "    range_4_6 = 0\n",
    "    range_6_8 = 0\n",
    "    range_8_10 = 0\n",
    "\n",
    "    # Iterate through the numbers and count occurrences in each range\n",
    "    for number in numbers:\n",
    "        if 0 <= number < 0.2:\n",
    "            range_0_2 += 1\n",
    "        elif 0.2 <= number < 0.4:\n",
    "            range_2_4 += 1\n",
    "        elif 0.4 <= number < 0.6:\n",
    "            range_4_6 += 1\n",
    "        elif 0.6 <= number < 0.8:\n",
    "            range_6_8 += 1\n",
    "        elif 0.8 <= number <= 1.0:\n",
    "            range_8_10 += 1\n",
    "\n",
    "    ranges = [range_0_2, range_2_4, range_4_6, range_6_8, range_8_10]\n",
    "    \n",
    "    return(np.array(ranges))\n",
    "\n",
    "def calculate_FS3_for_each_column(df, group_label):\n",
    "    \n",
    "    col = df.columns\n",
    "    colu = []\n",
    "    for c in col:\n",
    "        if (isfloat(df[c][0])):\n",
    "            colu.append(c)\n",
    "            \n",
    "    for c in colu:\n",
    "        df[c] = df[c].astype(float)\n",
    "    \n",
    "    string_columns_float = list(df.select_dtypes(exclude=['object']).columns)\n",
    "    string_columns_object = list(df.select_dtypes(include=['object']).columns)\n",
    "    \n",
    "    print(f\"Group label is: {group_label}\")\n",
    "    print(f\"Group label has {len(df[group_label].unique())} unique values\")\n",
    "    no_of_datasets = len(df[group_label].unique())\n",
    "    df = df.drop(labels=string_columns_object,axis=1)\n",
    "    list_of_datasets = []\n",
    "    origin_dict = {}\n",
    "    final_dict = {}\n",
    "\n",
    "    #creating separated datasetst for each group\n",
    "    for count,value in enumerate(df[group_label].unique()):\n",
    "        list_of_datasets.append( df[df[group_label] == value])\n",
    "        list_of_datasets[count] = list_of_datasets[count].reset_index()\n",
    "    \n",
    "    \n",
    "    #drop origin column for each group and save it as a key in dictionary where \n",
    "    #the value of the key will be the corresponding dataset\n",
    "    \n",
    "    for dataset in list_of_datasets:\n",
    "        \n",
    "        group = int(dataset[group_label].unique()[0])\n",
    "        \n",
    "        origin_dict[group] = dataset.drop(labels=[group_label],axis=1)\n",
    "        \n",
    "        columns = origin_dict[group].columns\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(origin_dict[group])\n",
    "        origin_dict[group] = scaler.transform(origin_dict[group])\n",
    "        origin_dict[group] = pd.DataFrame(origin_dict[group], columns = columns)\n",
    "        origin_dict[group] = origin_dict[group].drop(labels=[\"index\"] ,axis=1)\n",
    "\n",
    "        final_dict[group] = [calc_hist(origin_dict[group][c]) for c in origin_dict[group].columns]\n",
    "        \n",
    "    #calculation of diff and QDS between each combination of the groups.\n",
    "    diff = []\n",
    "\n",
    "    for key1, key2 in itertools.combinations(final_dict.keys(), 2):\n",
    "        diff.append(abs(np.subtract(np.array(final_dict[key1]),np.array(final_dict[key2]))))\n",
    "            \n",
    "    # print(diff)\n",
    "    \n",
    "    #creation of the matrix W\n",
    "    D = len(final_dict[1])\n",
    "    W = np.ones((D, D))\n",
    "        \n",
    "    for row in range(len(W)):\n",
    "        for col in range(len(W[0])):\n",
    "            dij = abs(row-col)\n",
    "            W[row][col] = 1 - (dij/(D-1))\n",
    "                        \n",
    "    #calculating QFD\n",
    "    QFD = []\n",
    "    for count,d in enumerate(diff):\n",
    "        # print(W.shape)\n",
    "        # print(d.shape)\n",
    "        # QFD.append(np.sqrt(np.dot(np.dot(d,W),np.transpose(d))))\n",
    "        QFD.append(np.sqrt(np.dot(np.dot(np.transpose(d),W),d)))\n",
    "        \n",
    "    TDS = sum(QFD)/len(QFD)\n",
    "    TDS = sum(TDS)/len(TDS)\n",
    "    TDS = sum(TDS)/len(TDS)\n",
    "    \n",
    "    return TDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ac3d4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group label is: origin\n",
      "Group label has 3 unique values\n",
      "150.19531329556122\n"
     ]
    }
   ],
   "source": [
    "print(calculate_FS3_for_each_column(cars,\"origin\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
